{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import citation_graph as citegrh\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import packages.transformer.data as transformer_data\n",
    "import packages.transformer.encoder_decoder as enc_dec\n",
    "import packages.transformer.attention as attention\n",
    "import packages.transformer.utils as utils\n",
    "importlib.reload(transformer_data)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(attention)\n",
    "importlib.reload(enc_dec)\n",
    "\n",
    "from packages.transformer.data import construct_batch, TransformerGraphBundleInput\n",
    "from packages.transformer.encoder_decoder import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "data = citegrh.load_cora()\n",
    "graph = data[0]\n",
    "adj = graph.adj(scipy_fmt='coo')\n",
    "graph = dgl.graph((adj.row, adj.col)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = (graph.adj(scipy_fmt='coo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsamir/anaconda3/lib/python3.9/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/tmp/ipykernel_429/325395223.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(data.features, device='cuda')\n",
      "/home/fsamir/anaconda3/lib/python3.9/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor(data.features, device='cuda')\n",
    "labels = torch.tensor(data.labels, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsamir/anaconda3/lib/python3.9/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "train_mask = torch.BoolTensor(data.train_mask)\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([3, 3])\n",
    "train_nids = (torch.arange(0, graph.number_of_nodes())[train_mask]).to('cuda')\n",
    "dataloader = dgl.dataloading.DataLoader(\n",
    "    graph, train_nids, sampler,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes_fb, output_nodes_fb, mfgs_fb = next(loader_iter)\n",
    "input_nodes_sb, output_nodes_sb, mfgs_sb = next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph_bundle_fb = construct_batch(output_nodes_fb, input_nodes_fb, mfgs_fb, features, labels, 'cpu')\n",
    "input_graph_bundle_sb = construct_batch(output_nodes_sb, input_nodes_sb, mfgs_sb, features, labels, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_graph_bundle(graph_bundle: TransformerGraphBundleInput) -> None: # WARNING: mutates graph bundle object\n",
    "    src_mask = graph_bundle.src_mask.squeeze(0) \n",
    "    size_subgraph = src_mask.shape[1]\n",
    "    padded_src_mask = torch.zeros((src_mask.shape[0], 512, 512))\n",
    "    padded_src_mask[:, : size_subgraph, : size_subgraph] = src_mask\n",
    "\n",
    "    src_feats = graph_bundle.src_feats.squeeze(0)\n",
    "    padded_src_feats = torch.zeros((512, src_feats.shape[-1]))\n",
    "    padded_src_feats[: size_subgraph, :src_feats.shape[-1]] = src_feats\n",
    "    graph_bundle.src_feats = padded_src_feats.unsqueeze(0)\n",
    "    graph_bundle.src_mask = padded_src_mask.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_graph_bundles(graph_bundles: List[TransformerGraphBundleInput]) -> TransformerGraphBundleInput:\n",
    "    src_masks = torch.cat([graph_bundle.src_mask for graph_bundle in graph_bundles])\n",
    "    src_feats = torch.cat([graph_bundle.src_feats for graph_bundle in graph_bundles])\n",
    "    trg_labels = torch.cat([graph_bundle.trg_labels for graph_bundle in graph_bundles])\n",
    "    train_inds = torch.cat([graph_bundle.train_inds for graph_bundle in graph_bundles])\n",
    "    return TransformerGraphBundleInput(src_feats, trg_labels, src_masks, train_inds, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_graph_bundle(input_graph_bundle_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_graph_bundle(input_graph_bundle_sb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_graph_bundle = stack_graph_bundles([input_graph_bundle_fb, input_graph_bundle_sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "torch.Size([2, 64])\n",
      "torch.Size([2, 512, 1433])\n",
      "torch.Size([2, 2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "stacked_graph_bundle.ntokens\n",
    "print(stacked_graph_bundle.ntokens)\n",
    "print(stacked_graph_bundle.train_inds.shape)\n",
    "print(stacked_graph_bundle.src_feats.shape)\n",
    "print(stacked_graph_bundle.src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsamir/gnn/packages/transformer/encoder_decoder.py:143: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "model = make_model(features.shape[1], len(labels.unique()) + 1, N=2) # +1 for the padding index, though I don't think it's necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "# model.forward(stacked_graph_bundle.src_feats, stacked_graph_bundle.src_mask, stacked_graph_bundle.train_inds)\n",
    "val = model.forward(stacked_graph_bundle.src_feats, stacked_graph_bundle.src_mask, stacked_graph_bundle.train_inds)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 512, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 2\n",
    "H = 8\n",
    "X = torch.randn((B, H, 512, 512))\n",
    "M = torch.zeros((B, 512, 512)) # an arbitrary mask\n",
    "\n",
    "X.masked_fill(M.unsqueeze(1) == 0, -1e9)\n",
    "X.masked_fill(M[:,None]==0,-1e9).shape\n",
    "\n",
    "\n",
    "# for batch_i in range(X.shape[0]): # looping over [1...B]\n",
    "# \tbatch_mask = M[batch_i]\n",
    "# \tfor j in range(X.shape[1]): # looping over [1...H]\n",
    "# \t\tX[batch_i, j] = X[batch_i, j].masked_fill(batch_mask == 0, -1e9) \n",
    "\n",
    "# X.masked_fill(M ==0, -1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_index_select(input, dim, index):\n",
    "\tviews = [input.shape[0]] + \\\n",
    "\t\t[1 if i != dim else -1 for i in range(1, len(input.shape))]\n",
    "\texpanse = list(input.shape)\n",
    "\texpanse[0] = -1\n",
    "\texpanse[dim] = -1\n",
    "\tindex = index.view(views).expand(expanse)\n",
    "\treturn torch.gather(input, dim, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 300])\n"
     ]
    }
   ],
   "source": [
    "# B = 2\n",
    "# SG_SIZE = 512\n",
    "# BS = 64\n",
    "# node_embeds = torch.rand((B, SG_SIZE, 300))\n",
    "# index = torch.randint(0, SG_SIZE, (2,BS))\n",
    "\n",
    "embeds = batched_index_select(node_embeds, 1, index)\n",
    "print(embeds.shape)\n",
    "# torch.gather(node_embeds, 0, index)\n",
    "# node_embeds[:,index].shape\n",
    "# print(index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4ebfc88ccd97cb231efe00c7198020b2ae0235bcff1ce31852dbbe06876d933"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
